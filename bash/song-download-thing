#!/bin/bash

#"We can't afford to host bulk downloads" they say
#...
#Well try and stop my script from doing it for me

#Constants that we will use for searching through the site
domain="https://somedomain.com"
trackname="some-album-name"
page="$domain/path/to/$trackname"
dlip="https://separate.download.somedomain.com/$trackname"

#A pseudo array that we will use so we don't get any repeat occurrences
# has a default value because it'd match everything without one
pseudoarray="BLUE"
#The regex to find the top layer links
regex="^.*(\/capture\/the\/$trackname\/.*\.mp3).*$"
#The regex to find the links inside the second layer of pages
innerregex="^.*($dlip\/$trackname\/.*\.mp3).*$"
mainsongtitleregex="<a href=\"\/capture\/the\/$trackname\/.*\.mp3\">(.*)</a>.*$"
pretitle=""

# Because who uses a real debugger when echo exists
#echo -e "domain: $domain\ntrackname: $trackname\npage: $page\ndlip: $dlip\n\nregex: $regex\ninnerregex: $innerregex\nmainsongtitleregex: $mainsongtitleregex" && exit 1

while read line
do
 if [[ $line == *"<a href=\"/path/to/$trackname/"* ]]; then
  #Honestly not sure why I did all the checking twice ¯\_(ツ)_/¯
  if [[ $line =~ $regex ]]; then
   mypath=${BASH_REMATCH[1]}
   #If we haven't visited the song page yet...
   if [[ $mypath != *$pseudoarray* ]]; then
    #Add the link to the array so we don't download it more than once
    pseudoarray+=" $mypath"
    if [[ $line =~ $mainsongtitleregex ]]; then
     pretitle=${BASH_REMATCH[1]}
    fi
    if [[ -f "$pretitle.mp3" ]]; then echo "SKIPPING $pretitle.mp3"; continue; else echo "NEED $pretitle"; fi;
################################# Start curling individual pages here #############################
    while read songline; do
     if [[ $songline == *"<a style=\"color: #123456;\" href=\"$dlip/$trackname/"*".mp3"* ]]; then
      if [[ $songline =~ $innerregex ]]; then
       songmatch=${BASH_REMATCH[1]}	#Not sure why this always returns an empty string
       #Grab the name of the directory the song file is in so we can save it
       dir=`echo $songline | cut -d"/" -f6`
       #Get the name so that we can change the output file name for wget
       name=`echo $songline | cut -d"/" -f7 | cut -d'"' -f1`
       #Clear out the space characters (and leave the others because it didn't work anyway)
       nicename=`echo $name | sed -e 's/%2520/ /g'`
       nicename=`echo $nicename | sed -e 's/%20/ /g'`
       nicename=`echo $nicename | sed -e 's/%23/#/g'`
       nicename=`echo $nicename | sed -e 's/%2C/,/g'`
       #Because wget doesn't have its own fancy schmancy progress bar for downloads
       if [[ -f "$nicename" ]]; then
	echo "-SKIPPING $nicename"
       else
        echo DOWNLOADING $nicename
        wget "$dlip/$dir/$name" -qO "$nicename"
       fi
      else
       echo - $songline
      fi
#     else echo "*$songline" # Warning, enabling this will spam your output
     fi
     #Curl doesn't output to stdout... which is fun...
    done < <(curl "$domain/$mypath" 2>&1)
###################################################################################################
   fi
   else
    echo - $line	#debug debug debug hooray
  fi
 fi
 #Why don't you use stdout :(
done < <(curl $page 2>&1)
